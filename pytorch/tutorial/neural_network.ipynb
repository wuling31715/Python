{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_n = 100\n",
    "hidden_layer = 100\n",
    "input_data = 1000\n",
    "output_data = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1000])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(batch_n, input_data)\n",
    "y = torch.randn(batch_n, output_data)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 100])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "w1 = torch.randn(input_data, hidden_layer)\n",
    "w2 = torch.randn(hidden_layer, output_data)\n",
    "print(w1.shape)\n",
    "print(w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: tensor(50865004.), y_true: tensor(1.6471), y_pred: tensor(615.6661)\n",
      "epoch: 100, loss: tensor(43341.0586), y_true: tensor(1.6471), y_pred: tensor(-1.2249)\n",
      "epoch: 200, loss: tensor(8607.0127), y_true: tensor(1.6471), y_pred: tensor(0.4496)\n",
      "epoch: 300, loss: tensor(2932.5850), y_true: tensor(1.6471), y_pred: tensor(1.1609)\n",
      "epoch: 400, loss: tensor(1229.3286), y_true: tensor(1.6471), y_pred: tensor(1.4198)\n",
      "epoch: 500, loss: tensor(628.3430), y_true: tensor(1.6471), y_pred: tensor(1.4608)\n",
      "epoch: 600, loss: tensor(380.9638), y_true: tensor(1.6471), y_pred: tensor(1.4663)\n",
      "epoch: 700, loss: tensor(259.8894), y_true: tensor(1.6471), y_pred: tensor(1.4684)\n",
      "epoch: 800, loss: tensor(192.2761), y_true: tensor(1.6471), y_pred: tensor(1.4757)\n",
      "epoch: 900, loss: tensor(149.2819), y_true: tensor(1.6471), y_pred: tensor(1.4839)\n"
     ]
    }
   ],
   "source": [
    "epoch_n = 1000\n",
    "learning_rate = 1e-6\n",
    "for i in range(epoch_n):\n",
    "    h1 = x.mm(w1) # (100, 100) = (100, 1000) * (1000, 100)\n",
    "    h1 = h1.clamp(min=0) # ReLu\n",
    "    y_pred = h1.mm(w2) # (100, 10) = (100, 100) * (100, 10)\n",
    "    loss = (y_pred - y).pow(2).sum() # SE\n",
    "    if i % 100 == 0:\n",
    "        print('epoch: %s, loss: %s, y_true: %s, y_pred: %s' % (str(i), str(loss), str(y[0][0]), str(y_pred[0][0])))\n",
    "    grad_y_pred = 2 * (y_pred - y)\n",
    "    # grad_w2\n",
    "    grda_w2 = h1.t().mm(grad_y_pred)\n",
    "    grad_h = grad_y_pred.clone()\n",
    "    grad_h = grad_h.mm(w2.t())\n",
    "    grad_h.clamp(min=0)\n",
    "    # grad_w1    \n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grda_w2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### aotograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_n = 100\n",
    "hidden_layer = 100\n",
    "input_data = 1000\n",
    "output_data = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1000])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(batch_n, input_data), requires_grad=False)\n",
    "y = Variable(torch.randn(batch_n, output_data), requires_grad=False)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 100])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "w1 = Variable(torch.randn(input_data, hidden_layer), requires_grad=True)\n",
    "w2 = Variable(torch.randn(hidden_layer, output_data), requires_grad=True)\n",
    "print(w1.shape)\n",
    "print(w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: tensor(40722936., grad_fn=<SumBackward0>), y_true: tensor(-0.8257), y_pred: tensor(96.6597, grad_fn=<SelectBackward>)\n",
      "epoch: 100, loss: tensor(41216.3125, grad_fn=<SumBackward0>), y_true: tensor(-0.8257), y_pred: tensor(-1.9019, grad_fn=<SelectBackward>)\n",
      "epoch: 200, loss: tensor(9559.8496, grad_fn=<SumBackward0>), y_true: tensor(-0.8257), y_pred: tensor(-0.5099, grad_fn=<SelectBackward>)\n",
      "epoch: 300, loss: tensor(3520.5991, grad_fn=<SumBackward0>), y_true: tensor(-0.8257), y_pred: tensor(-0.0955, grad_fn=<SelectBackward>)\n",
      "epoch: 400, loss: tensor(1603.3752, grad_fn=<SumBackward0>), y_true: tensor(-0.8257), y_pred: tensor(-0.0625, grad_fn=<SelectBackward>)\n",
      "epoch: 500, loss: tensor(851.7950, grad_fn=<SumBackward0>), y_true: tensor(-0.8257), y_pred: tensor(-0.1455, grad_fn=<SelectBackward>)\n",
      "epoch: 600, loss: tensor(513.6158, grad_fn=<SumBackward0>), y_true: tensor(-0.8257), y_pred: tensor(-0.2597, grad_fn=<SelectBackward>)\n",
      "epoch: 700, loss: tensor(343.4406, grad_fn=<SumBackward0>), y_true: tensor(-0.8257), y_pred: tensor(-0.3644, grad_fn=<SelectBackward>)\n",
      "epoch: 800, loss: tensor(249.3489, grad_fn=<SumBackward0>), y_true: tensor(-0.8257), y_pred: tensor(-0.4489, grad_fn=<SelectBackward>)\n",
      "epoch: 900, loss: tensor(193.3146, grad_fn=<SumBackward0>), y_true: tensor(-0.8257), y_pred: tensor(-0.5157, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "epoch_n = 1000\n",
    "learning_rate = 1e-6\n",
    "for i in range(epoch_n):\n",
    "    h1 = x.mm(w1) # (100, 100) = (100, 1000) * (1000, 100) \n",
    "    h1 = h1.clamp(min=0) # ReLu\n",
    "    y_pred = h1.mm(w2) # (100, 10) = (100, 100) * (100, 10)\n",
    "    loss = (y_pred - y).pow(2).sum() # SE\n",
    "    if i % 100 == 0:\n",
    "        print('epoch: %s, loss: %s, y_true: %s, y_pred: %s' % (str(i), str(loss), str(y[0][0]), str(y_pred[0][0])))\n",
    "    loss.backward()\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model()\n"
     ]
    }
   ],
   "source": [
    "class Model(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        \n",
    "    def forward(self, input_data, w1, w2):\n",
    "        x = torch.mm(input_data, w1) # h1 = input * w1\n",
    "        x = torch.clamp(x, min=0) # ReLu\n",
    "        x = torch.mm(x, w2) # y = h1 * w2\n",
    "        return x\n",
    "    \n",
    "    def backward(self):\n",
    "        pass\n",
    "\n",
    "model = Model()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_n = 100\n",
    "hidden_layer = 100\n",
    "input_data = 1000\n",
    "output_data = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1000])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(batch_n, input_data), requires_grad=False)\n",
    "y = Variable(torch.randn(batch_n, output_data), requires_grad=False)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1000, 100])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "w1 = Variable(torch.randn(input_data, hidden_layer), requires_grad=True)\n",
    "w2 = Variable(torch.randn(hidden_layer, output_data), requires_grad=True)\n",
    "print(w1.shape)\n",
    "print(w2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: tensor(42468268., grad_fn=<SumBackward0>), y_true: tensor(1.0570), y_pred: tensor(79.8385, grad_fn=<SelectBackward>)\n",
      "epoch: 100, loss: tensor(55786.7578, grad_fn=<SumBackward0>), y_true: tensor(1.0570), y_pred: tensor(-10.0055, grad_fn=<SelectBackward>)\n",
      "epoch: 200, loss: tensor(15443.3662, grad_fn=<SumBackward0>), y_true: tensor(1.0570), y_pred: tensor(-5.3197, grad_fn=<SelectBackward>)\n",
      "epoch: 300, loss: tensor(7095.4106, grad_fn=<SumBackward0>), y_true: tensor(1.0570), y_pred: tensor(-3.0542, grad_fn=<SelectBackward>)\n",
      "epoch: 400, loss: tensor(3965.4519, grad_fn=<SumBackward0>), y_true: tensor(1.0570), y_pred: tensor(-1.8260, grad_fn=<SelectBackward>)\n",
      "epoch: 500, loss: tensor(2469.5662, grad_fn=<SumBackward0>), y_true: tensor(1.0570), y_pred: tensor(-1.0806, grad_fn=<SelectBackward>)\n",
      "epoch: 600, loss: tensor(1659.4929, grad_fn=<SumBackward0>), y_true: tensor(1.0570), y_pred: tensor(-0.5815, grad_fn=<SelectBackward>)\n",
      "epoch: 700, loss: tensor(1173.9072, grad_fn=<SumBackward0>), y_true: tensor(1.0570), y_pred: tensor(-0.2272, grad_fn=<SelectBackward>)\n",
      "epoch: 800, loss: tensor(861.8925, grad_fn=<SumBackward0>), y_true: tensor(1.0570), y_pred: tensor(0.0226, grad_fn=<SelectBackward>)\n",
      "epoch: 900, loss: tensor(651.8082, grad_fn=<SumBackward0>), y_true: tensor(1.0570), y_pred: tensor(0.2136, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "epoch_n = 1000\n",
    "learning_rate = 1e-6\n",
    "for i in range(epoch_n):\n",
    "    h1 = x.mm(w1) # h1 = x * w1\n",
    "    h1 = h1.clamp(min=0) # ReLu\n",
    "    y_pred = model(x, w1, w2) # y = x * w1 *w2\n",
    "    loss = (y_pred - y).pow(2).sum() # SE\n",
    "    if i % 100 == 0:\n",
    "        print('epoch: %s, loss: %s, y_true: %s, y_pred: %s' % (str(i), str(loss), str(y[0][0]), str(y_pred[0][0])))\n",
    "    loss.backward()\n",
    "    w1.data -= learning_rate * w1.grad.data\n",
    "    w2.data -= learning_rate * w2.grad.data\n",
    "    w1.grad.data.zero_()\n",
    "    w2.grad.data.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_data, hidden_layer), # w1\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_layer, output_data) # w2\n",
    ")\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_n = 100\n",
    "hidden_layer = 100\n",
    "input_data = 1000\n",
    "output_data = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1000])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(batch_n, input_data), requires_grad=False)\n",
    "y = Variable(torch.randn(batch_n, output_data), requires_grad=False)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: tensor(1.0343, grad_fn=<MseLossBackward>), y_true: tensor(-0.6250), y_pred: tensor(-0.0283, grad_fn=<SelectBackward>)\n",
      "epoch: 1000, loss: tensor(0.9531, grad_fn=<MseLossBackward>), y_true: tensor(-0.6250), y_pred: tensor(-0.0290, grad_fn=<SelectBackward>)\n",
      "epoch: 2000, loss: tensor(0.8838, grad_fn=<MseLossBackward>), y_true: tensor(-0.6250), y_pred: tensor(-0.0289, grad_fn=<SelectBackward>)\n",
      "epoch: 3000, loss: tensor(0.8231, grad_fn=<MseLossBackward>), y_true: tensor(-0.6250), y_pred: tensor(-0.0308, grad_fn=<SelectBackward>)\n",
      "epoch: 4000, loss: tensor(0.7695, grad_fn=<MseLossBackward>), y_true: tensor(-0.6250), y_pred: tensor(-0.0364, grad_fn=<SelectBackward>)\n",
      "epoch: 5000, loss: tensor(0.7215, grad_fn=<MseLossBackward>), y_true: tensor(-0.6250), y_pred: tensor(-0.0423, grad_fn=<SelectBackward>)\n",
      "epoch: 6000, loss: tensor(0.6783, grad_fn=<MseLossBackward>), y_true: tensor(-0.6250), y_pred: tensor(-0.0502, grad_fn=<SelectBackward>)\n",
      "epoch: 7000, loss: tensor(0.6386, grad_fn=<MseLossBackward>), y_true: tensor(-0.6250), y_pred: tensor(-0.0618, grad_fn=<SelectBackward>)\n",
      "epoch: 8000, loss: tensor(0.6017, grad_fn=<MseLossBackward>), y_true: tensor(-0.6250), y_pred: tensor(-0.0765, grad_fn=<SelectBackward>)\n",
      "epoch: 9000, loss: tensor(0.5674, grad_fn=<MseLossBackward>), y_true: tensor(-0.6250), y_pred: tensor(-0.0917, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "epoch_n = 10000\n",
    "learning_rate = 1e-4\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "for i in range(epoch_n):\n",
    "    y_pred = models(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if i % 1000 == 0:\n",
    "        print('epoch: %s, loss: %s, y_true: %s, y_pred: %s' % (str(i), str(loss), str(y[0][0]), str(y_pred[0][0])))\n",
    "    loss.backward()\n",
    "    for j in models.parameters():\n",
    "        j.data -= learning_rate * j.grad.data\n",
    "    models.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Linear(in_features=1000, out_features=100, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=100, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "models = torch.nn.Sequential(\n",
    "    torch.nn.Linear(input_data, hidden_layer), # w1\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(hidden_layer, output_data) # w2\n",
    ")\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_n = 100\n",
    "hidden_layer = 100\n",
    "input_data = 1000\n",
    "output_data = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1000])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "x = Variable(torch.randn(batch_n, input_data), requires_grad=False)\n",
    "y = Variable(torch.randn(batch_n, output_data), requires_grad=False)\n",
    "print(x.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss: tensor(1.0492, grad_fn=<MseLossBackward>), y_true: tensor(0.1126), y_pred: tensor(0.0124, grad_fn=<SelectBackward>)\n",
      "epoch: 1000, loss: tensor(1.8917e-14, grad_fn=<MseLossBackward>), y_true: tensor(0.1126), y_pred: tensor(0.1126, grad_fn=<SelectBackward>)\n",
      "epoch: 2000, loss: tensor(3.1021e-15, grad_fn=<MseLossBackward>), y_true: tensor(0.1126), y_pred: tensor(0.1126, grad_fn=<SelectBackward>)\n",
      "epoch: 3000, loss: tensor(3.9565e-15, grad_fn=<MseLossBackward>), y_true: tensor(0.1126), y_pred: tensor(0.1126, grad_fn=<SelectBackward>)\n",
      "epoch: 4000, loss: tensor(4.5731e-15, grad_fn=<MseLossBackward>), y_true: tensor(0.1126), y_pred: tensor(0.1126, grad_fn=<SelectBackward>)\n",
      "epoch: 5000, loss: tensor(5.9083e-15, grad_fn=<MseLossBackward>), y_true: tensor(0.1126), y_pred: tensor(0.1126, grad_fn=<SelectBackward>)\n",
      "epoch: 6000, loss: tensor(9.2542e-15, grad_fn=<MseLossBackward>), y_true: tensor(0.1126), y_pred: tensor(0.1126, grad_fn=<SelectBackward>)\n",
      "epoch: 7000, loss: tensor(1.4840e-14, grad_fn=<MseLossBackward>), y_true: tensor(0.1126), y_pred: tensor(0.1126, grad_fn=<SelectBackward>)\n",
      "epoch: 8000, loss: tensor(2.5903e-14, grad_fn=<MseLossBackward>), y_true: tensor(0.1126), y_pred: tensor(0.1126, grad_fn=<SelectBackward>)\n",
      "epoch: 9000, loss: tensor(2.2833e-11, grad_fn=<MseLossBackward>), y_true: tensor(0.1126), y_pred: tensor(0.1126, grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "epoch_n = 10000\n",
    "learning_rate = 1e-4\n",
    "loss_fn = torch.nn.MSELoss()\n",
    "optimzer = torch.optim.Adam(models.parameters(), lr=learning_rate)\n",
    "for i in range(epoch_n):\n",
    "    y_pred = models(x)\n",
    "    loss = loss_fn(y_pred, y)\n",
    "    if i % 1000 == 0:\n",
    "        print('epoch: %s, loss: %s, y_true: %s, y_pred: %s' % (str(i), str(loss), str(y[0][0]), str(y_pred[0][0])))\n",
    "    optimzer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimzer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6",
   "language": "python",
   "name": "py3.6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
