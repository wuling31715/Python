{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python version: 3.6\n",
    "* conda create --name py3.6 python=3.6\n",
    "* source activate py3.6\n",
    "* python -V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Java version:  8\n",
    "* brew cask install adoptopenjdk/openjdk/adoptopenjdk8\n",
    "* open ~/.bash_profile\n",
    "* export JAVA_HOME=$(/usr/libexec/java_home -v 1.8)\n",
    "* java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 01: Import Spark Session and initialize Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "...     .master(\"local\") \\\n",
    "...     .appName(\"Weather Forecast\") \\\n",
    "...     .config(\"spark.some.config.option\", \"some-value\") \\\n",
    "...     .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 02: Load the dataset and print the schema and total number of entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('weatherAUS.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(summary='count', Date='142193', Location='142193', MinTemp='142193', MaxTemp='142193', Rainfall='142193', Evaporation='142193', Sunshine='142193', WindGustDir='142193', WindGustSpeed='142193', WindDir9am='142193', WindDir3pm='142193', WindSpeed9am='142193', WindSpeed3pm='142193', Humidity9am='142193', Humidity3pm='142193', Pressure9am='142193', Pressure3pm='142193', Cloud9am='142193', Cloud3pm='142193', Temp9am='142193', Temp3pm='142193', RainToday='142193', RainTomorrow='142193'),\n",
       " Row(summary='mean', Date=None, Location=None, MinTemp='12.186399728729098', MaxTemp='23.226784191272444', Rainfall='2.3499740743111954', Evaporation='5.469824216349123', Sunshine='7.624853113193571', WindGustDir=None, WindGustSpeed='39.98429165757619', WindDir9am=None, WindDir3pm=None, WindSpeed9am='14.001988000994', WindSpeed3pm='18.63757586179718', Humidity9am='68.8438103105705', Humidity3pm='51.482606091656265', Pressure9am='1017.6537584159781', Pressure3pm='1015.258203537907', Cloud9am='4.437189391885787', Cloud3pm='4.503166899728551', Temp9am='16.98750858170133', Temp3pm='21.68723497314744', RainToday=None, RainTomorrow=None),\n",
       " Row(summary='stddev', Date=None, Location=None, MinTemp='6.403282674671314', MaxTemp='7.117618141018136', Rainfall='8.465172917616425', Evaporation='4.188536508895149', Sunshine='3.7815249942144615', WindGustDir=None, WindGustSpeed='13.588800765487752', WindDir9am=None, WindDir3pm=None, WindSpeed9am='8.893337098234603', WindSpeed3pm='8.803345036235537', Humidity9am='19.051292535336177', Humidity3pm='20.79777184369888', Pressure9am='7.105475711520505', Pressure3pm='7.0366767834928545', Cloud9am='2.8870155257335974', Cloud3pm='2.720632530403652', Temp9am='6.492838325478915', Temp3pm='6.9375938685337335', RainToday=None, RainTomorrow=None),\n",
       " Row(summary='min', Date='2007-11-01', Location='Adelaide', MinTemp='-0.1', MaxTemp='-0.1', Rainfall='0', Evaporation='0', Sunshine='0', WindGustDir='E', WindGustSpeed='100', WindDir9am='E', WindDir3pm='E', WindSpeed9am='0', WindSpeed3pm='0', Humidity9am='0', Humidity3pm='0', Pressure9am='1.00E+03', Pressure3pm='1.00E+03', Cloud9am='0', Cloud3pm='0', Temp9am='-0.1', Temp3pm='-0.1', RainToday='NA', RainTomorrow='No'),\n",
       " Row(summary='max', Date='2017-06-25', Location='Woomera', MinTemp='NA', MaxTemp='NA', Rainfall='NA', Evaporation='NA', Sunshine='NA', WindGustDir='WSW', WindGustSpeed='NA', WindDir9am='WSW', WindDir3pm='WSW', WindSpeed9am='NA', WindSpeed3pm='NA', Humidity9am='NA', Humidity3pm='NA', Pressure9am='NA', Pressure3pm='NA', Cloud9am='NA', Cloud3pm='NA', Temp9am='NA', Temp3pm='NA', RainToday='Yes', RainTomorrow='Yes')]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv('weatherAUS.csv', header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Location: string (nullable = true)\n",
      " |-- MinTemp: string (nullable = true)\n",
      " |-- MaxTemp: string (nullable = true)\n",
      " |-- Rainfall: string (nullable = true)\n",
      " |-- Evaporation: string (nullable = true)\n",
      " |-- Sunshine: string (nullable = true)\n",
      " |-- WindGustDir: string (nullable = true)\n",
      " |-- WindGustSpeed: string (nullable = true)\n",
      " |-- WindDir9am: string (nullable = true)\n",
      " |-- WindDir3pm: string (nullable = true)\n",
      " |-- WindSpeed9am: string (nullable = true)\n",
      " |-- WindSpeed3pm: string (nullable = true)\n",
      " |-- Humidity9am: string (nullable = true)\n",
      " |-- Humidity3pm: string (nullable = true)\n",
      " |-- Pressure9am: string (nullable = true)\n",
      " |-- Pressure3pm: string (nullable = true)\n",
      " |-- Cloud9am: string (nullable = true)\n",
      " |-- Cloud3pm: string (nullable = true)\n",
      " |-- Temp9am: string (nullable = true)\n",
      " |-- Temp3pm: string (nullable = true)\n",
      " |-- RainToday: string (nullable = true)\n",
      " |-- RainTomorrow: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142193"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 03: Delete columns from the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|   13.4|   22.9|     0.6|          W|           44|         W|       WNW|          20|          24|         71|         22|     1007.7|     1007.1|       No|          No|\n",
      "|    7.4|   25.1|       0|        WNW|           44|       NNW|       WSW|           4|          22|         44|         25|     1010.6|     1007.8|       No|          No|\n",
      "|   12.9|   25.7|       0|        WSW|           46|         W|       WSW|          19|          26|         38|         30|     1007.6|     1008.7|       No|          No|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop('Date', 'Location', 'Evaporation', 'Sunshine', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm')\n",
    "df.show(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 04: Print the number of missing data in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|MinTemp|MaxTemp|Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|    637|    322|    1406|       9330|         9270|     10013|      3778|        1348|        2630|       1774|       3610|      14014|      13981|     1406|           0|\n",
      "+-------+-------+--------+-----------+-------------+----------+----------+------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col,sum\n",
    "df.select(*(sum(col(c).isin('NA').cast(\"int\")).alias(c) for c in df.columns)).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 05: Fill the missing data with average value and maximum occurrence value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+------------------+------------------+------------------+-----------------+-----------------+----------------+------------------+------------------+-----------------+\n",
      "|      avg(MinTemp)|      avg(MaxTemp)|     avg(Rainfall)|avg(WindGustSpeed)|avg(WindSpeed9am)|avg(WindSpeed3pm)|avg(Humidity9am)|  avg(Humidity3pm)|  avg(Pressure9am)| avg(Pressure3pm)|\n",
      "+------------------+------------------+------------------+------------------+-----------------+-----------------+----------------+------------------+------------------+-----------------+\n",
      "|12.186399728729098|23.226784191272444|2.3499740743111954| 39.98429165757619|  14.001988000994|18.63757586179718|68.8438103105705|51.482606091656265|1017.6537584159781|1015.258203537907|\n",
      "+------------------+------------------+------------------+------------------+-----------------+-----------------+----------------+------------------+------------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import countDistinct, avg, stddev, min, max, sum, count \n",
    "df.select(avg('MinTemp'),\n",
    "          avg('MaxTemp'),\n",
    "          avg('Rainfall'),\n",
    "          avg('WindGustSpeed'),\n",
    "          avg('WindSpeed9am'),\n",
    "          avg('WindSpeed3pm'),\n",
    "          avg('Humidity9am'),\n",
    "          avg('Humidity3pm'),\n",
    "          avg('Pressure9am'),\n",
    "          avg('Pressure3pm')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_list = df.select(avg('MinTemp'), \n",
    "                     avg('MaxTemp'), \n",
    "                     avg('Rainfall'), \n",
    "                     avg('WindGustSpeed'), \n",
    "                     avg('WindSpeed9am'), \n",
    "                     avg('WindSpeed3pm'), \n",
    "                     avg('Humidity9am'), \n",
    "                     avg('Humidity3pm'), \n",
    "                     avg('Pressure9am'), \n",
    "                     avg('Pressure3pm')).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+---------------+---------------+--------------+-----------------+\n",
      "|max(WindGustDir)|max(WindDir9am)|max(WindDir3pm)|max(RainToday)|max(RainTomorrow)|\n",
      "+----------------+---------------+---------------+--------------+-----------------+\n",
      "|             WSW|            WSW|            WSW|           Yes|              Yes|\n",
      "+----------------+---------------+---------------+--------------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(max('WindGustDir'),\n",
    "          max('WindDir9am'),\n",
    "          max('WindDir3pm'),\n",
    "          max('RainToday'),\n",
    "          max('RainTomorrow'),\n",
    "         ).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_list = df.select(max('WindGustDir'),\n",
    "                     max('WindDir9am'),\n",
    "                     max('WindDir3pm'),\n",
    "                     max('RainToday'),\n",
    "                     max('RainTomorrow'),\n",
    "                    ).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------+-----------+-------------+----------+----------+---------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|MinTemp|MaxTemp|          Rainfall|WindGustDir|WindGustSpeed|WindDir9am|WindDir3pm|   WindSpeed9am|WindSpeed3pm|Humidity9am|Humidity3pm|Pressure9am|Pressure3pm|RainToday|RainTomorrow|\n",
      "+-------+-------+------------------+-----------+-------------+----------+----------+---------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "|   13.4|   22.9|               0.6|          W|           44|         W|       WNW|             20|          24|         71|         22|     1007.7|     1007.1|       No|          No|\n",
      "|    7.4|   25.1|                 0|        WNW|           44|       NNW|       WSW|              4|          22|         44|         25|     1010.6|     1007.8|       No|          No|\n",
      "|   12.9|   25.7|                 0|        WSW|           46|         W|       WSW|             19|          26|         38|         30|     1007.6|     1008.7|       No|          No|\n",
      "|    9.2|     28|                 0|         NE|           24|        SE|         E|             11|           9|         45|         16|     1017.6|     1012.8|       No|          No|\n",
      "|   17.5|   32.3|                 1|          W|           41|       ENE|        NW|              7|          20|         82|         33|     1010.8|       1006|       No|          No|\n",
      "|   14.6|   29.7|               0.2|        WNW|           56|         W|         W|             19|          24|         55|         23|     1009.2|     1005.4|       No|          No|\n",
      "|   14.3|     25|                 0|          W|           50|        SW|         W|             20|          24|         49|         19|     1009.6|     1008.2|       No|          No|\n",
      "|    7.7|   26.7|                 0|          W|           35|       SSE|         W|              6|          17|         48|         19|     1013.4|     1010.1|       No|          No|\n",
      "|    9.7|   31.9|                 0|        NNW|           80|        SE|        NW|              7|          28|         42|          9|     1008.9|     1003.6|       No|         Yes|\n",
      "|   13.1|   30.1|               1.4|          W|           28|         S|       SSE|             15|          11|         58|         27|       1007|     1005.7|      Yes|          No|\n",
      "|   13.4|   30.4|                 0|          N|           30|       SSE|       ESE|             17|           6|         48|         22|     1011.8|     1008.7|       No|         Yes|\n",
      "|   15.9|   21.7|               2.2|        NNE|           31|        NE|       ENE|             15|          13|         89|         91|     1010.5|     1004.2|      Yes|         Yes|\n",
      "|   15.9|   18.6|              15.6|          W|           61|       NNW|       NNW|             28|          28|         76|         93|      994.3|        993|      Yes|         Yes|\n",
      "|   12.6|     21|               3.6|         SW|           44|         W|       SSW|             24|          20|         65|         43|     1001.2|     1001.8|      Yes|          No|\n",
      "|    9.8|   27.7|2.3499740743111954|        WNW|           50|       WSW|       WNW|14.001988000994|          22|         50|         28|     1013.4|     1010.3|      Yes|          No|\n",
      "|   14.1|   20.9|                 0|        ENE|           22|       SSW|         E|             11|           9|         69|         82|     1012.2|     1010.4|       No|         Yes|\n",
      "|   13.5|   22.9|              16.8|          W|           63|         N|       WNW|              6|          20|         80|         65|     1005.8|     1002.2|      Yes|         Yes|\n",
      "|   11.2|   22.5|              10.6|        SSE|           43|       WSW|        SW|             24|          17|         47|         32|     1009.4|     1009.7|      Yes|          No|\n",
      "|    9.8|   25.6|                 0|        SSE|           26|        SE|       NNW|             17|           6|         45|         26|     1019.2|     1017.1|       No|          No|\n",
      "|   11.5|   29.3|                 0|          S|           24|        SE|        SE|              9|           9|         56|         28|     1019.3|     1014.8|       No|          No|\n",
      "+-------+-------+------------------+-----------+-------------+----------+----------+---------------+------------+-----------+-----------+-----------+-----------+---------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df2 = df\\\n",
    ".withColumn('MinTemp', when(df.MinTemp=='NA', avg_list[0][0]).otherwise(df.MinTemp))\\\n",
    ".withColumn('MaxTemp', when(df.MaxTemp=='NA', avg_list[0][1]).otherwise(df.MaxTemp))\\\n",
    ".withColumn('Rainfall', when(df.Rainfall=='NA', avg_list[0][2]).otherwise(df.Rainfall))\\\n",
    ".withColumn('WindGustSpeed', when(df.WindGustSpeed=='NA', avg_list[0][3]).otherwise(df.WindGustSpeed))\\\n",
    ".withColumn('WindSpeed9am', when(df.WindSpeed9am=='NA', avg_list[0][4]).otherwise(df.WindSpeed9am))\\\n",
    ".withColumn('WindSpeed3pm', when(df.WindSpeed3pm=='NA', avg_list[0][5]).otherwise(df.WindSpeed3pm))\\\n",
    ".withColumn('Humidity9am', when(df.Humidity9am=='NA', avg_list[0][6]).otherwise(df.Humidity9am))\\\n",
    ".withColumn('Humidity3pm', when(df.Humidity3pm=='NA', avg_list[0][7]).otherwise(df.Humidity3pm))\\\n",
    ".withColumn('Pressure9am', when(df.Pressure9am=='NA', avg_list[0][8]).otherwise(df.Pressure9am))\\\n",
    ".withColumn('Pressure3pm', when(df.Pressure3pm=='NA', avg_list[0][9]).otherwise(df.Pressure3pm))\\\n",
    ".withColumn('WindGustDir', when(df.WindGustDir=='NA', max_list[0][0]).otherwise(df.WindGustDir))\\\n",
    ".withColumn('WindDir9am', when(df.WindDir9am=='NA', max_list[0][1]).otherwise(df.WindDir9am))\\\n",
    ".withColumn('WindDir3pm', when(df.WindDir3pm=='NA', max_list[0][2]).otherwise(df.WindDir3pm))\\\n",
    ".withColumn('RainToday', when(df.RainToday=='NA', max_list[0][3]).otherwise(df.RainToday))\\\n",
    ".withColumn('RainTomorrow', when(df.RainTomorrow=='NA', max_list[0][4]).otherwise(df.RainTomorrow))\\\n",
    "\n",
    "df2.show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 06: Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 07: Create the feature vector and divide the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 08: Apply machine learning classification algorithms on the dataset and compare their accuracy. Plot the accuracy as bar graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 09: Calculate the confusion matrix and find the precision, recall, and F1 score of each classification algorithm. Explain how the accuracy of the predication can be improved?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
